# Spring AI Alibaba RAG 服务（Stage 1）产品需求文档

## 1. 背景与目标
- 现状：当前项目为 DashScope 单轮聊天脚手架，缺乏企业知识支撑，无法覆盖手机 App 智能助手的多场景需求。
- 痛点：标准模型回答不具备产品上下文，易出现幻觉且难以追溯；移动端用户期望个性化语气与更丰富的业务能力（设备控制、耗材提醒等）。
- 目标：构建 Stage 1 RAG 服务，提供“检索 + 生成”的可信回答，支持多渠道/多角色语气控制，为后续扩展设备控制、场景联动、售后智能体奠定基础。

## 2. 使用场景与用户
- 客服代表：快速查询设备重置、安装、故障排查步骤。
- 内部支持工程师：获取保修政策、技术公告、工单处理案例。
- 手机 App 智能助手：面向终端客户，需覆盖产品问答、售后政策、设备工作状态说明，并为未来的设备/场景控制、耗材提醒、生活闲聊等功能提供知识底座与语气定制能力。
- API 调用方：为机器人/智能体提供带引用的回答能力，并可按渠道、角色控制回答风格。

## 3. 功能范围（Stage 1）

### 3.1 知识语料管理
- 数据来源：产品手册、FAQ、工单摘要、公告等文本/HTML/PDF/Markdown。
- 清洗与分块：
  - 统一转为 UTF-8 文本，保留结构信息。
  - 分块策略：
    - 结构化优先：Markdown 按标题层级、HTML 按 `<p>/<li>/<table>` 等标签切分。
    - 长度约束：单块 300–500 字（字符），每块与前后块重叠 80–100 字，以保留语义上下文。
  - 保留元数据：`document_id`、`title`、`section`、`page_number`、`url`、`last_modified_at`、`tags`。
- 向量化：默认 DashScope `text-embedding-v2`，抽象接口便于替换。
- 存储：首选 Postgres + pgvector，记录向量、元数据、摘要、embedding 版本。
- 导入流程：手动触发脚本完成批量导入，并预留增量更新入口；导入时需按 `document_id` 先失效（删除）旧分块，再写入最新内容，保证知识一致性。

### 3.2 检索增强生成（RAG Pipeline）
- 流程：
  1. Query 预处理（清理、语言检测、指代消解）。
  2. Query 重写（规则触发：代词、多主题问题、渠道特定改写等）。
     - 若请求未显式传递 `capabilities`，默认执行标准知识检索；生成回答可以建议用户在 App 中的操作路径，但不触发任何外部工具调用。
  3. 检索：向量检索 + 过滤（top-k=5），按得分加权重排序；权重策略默认以向量相似度为主，并可结合业务规则（如最近更新时间、官方公告优先）作轻量加权，为后续引入 Cross-Encoder 作准备。
  4. 回答生成：
     - Prompt 需根据 `persona`/`channel` 动态拼装：包含系统指令、语气（如“智能助手以亲和语气回答客户”）、检索上下文（含段落 ID 与引用）、用户问题及必要的安全约束。
     - 指令：若上下文不足以回答，需直接说明“根据现有知识库，我暂时无法回答”，并提示可能的后续操作（如转人工或查看设备控制面板）。
  5. 返回：`answer`、`references`（`document_id`、`title`、`url`、`chunk_snippet`）、`confidence`、`request_id`、`persona`（回显）；`confidence` 建议基于检索得分计算（例如 `0.8 × top1_score + 0.2 × avg_top3_score`），低于阈值时附带“可能不准确”提示。

### 3.3 服务接口
- `POST /api/rag/query`：请求体需包含
  - `question`、`top_k`、`filters`
  - `channel`（如 `app`, `csr`, `bot`）与 `persona`（如“亲和客服”“专业工程师”），用于控制语气、回答长度、是否追加行动指引。
    - `persona` 模板建议配置化（YAML 或配置中心），并提供只读查询能力（如 `/api/rag/personas` 或内部配置文档）以便运营查看和热更新。
  - 可选 `capabilities`（枚举，标记调用方希望触达的功能域，如 `device_status`, `consumable`, `scene_control`，Stage 1 用于知识检索过滤，后续用于触发工具调用）。
  响应包含答案、引用、置信度、耗时、`request_id`、`persona` 回显。
- `POST /api/rag/feedback`：请求体含 `request_id`、`is_helpful`、`correction`（可选）、`reason`（枚举值）。
- `GET /actuator/health`：监测检索、模型调用、数据库连通性。
- 鉴权：初期使用 API Key，后续可升级 OAuth2/网关。

### 3.4 运营与可观测性
- 请求日志记录：请求（脱敏）、检索命中、引用 ID、耗时、API Cost。
- 指标监控：检索耗时、模型耗时、成功率、Token 消耗、Top-k 点击率。
- 告警：DashScope 限流/失败、向量库不可用、回答置信度低于阈值。

## 4. 非功能性需求
- 性能：平均响应 ≤2.5 秒，P95 ≤4 秒（top-k=5）。
- 可用性：99%，失败自动重试一次（退避策略）。
- 安全：日志脱敏、访问控制；反馈接口限制权限。
- 扩展性：模块化设计，便于替换向量库、Embedding、生成模型；预留租户支持。

## 5. KPI 与评估
- Faithfulness（忠实度）≥85%：基于黄金样本人工评估。
- Answer Relevancy（相关性）≥80%。
- Context Precision（上下文精确度）≥75%。
- 用户反馈满意度 ≥80%。
- 系统指标：平均耗时 ≤2.5 秒，成功率 ≥99%，日请求量 ≥100。
- 业务指标（参考）：App 智能助手渠道“问题转人工率”或“帮助中心工单提交率”呈下降趋势，用以衡量知识服务对业务的支撑效果。

## 6. 用户故事
1. 客服：查询“XX 型号空调如何重置？”→ 获得步骤+文档引用。
2. 工程师：查询“保修期如何判定？”→ 返回政策条款与链接。
3. App 用户：在手机助手中询问“我家客厅净水器滤芯还剩多久需要更换？”→ 以亲和语气返回保养周期、当前状态查询方式，并提示可在“耗材管理”中查看详情。
4. 运营：对响应提交“不满意”反馈→ 后台可追踪修正。

## 7. 风险与对策
| 风险 | 影响 | 对策 |
| --- | --- | --- |
| 数据质量欠佳 | 回答噪声高 | 制定清洗规则、人工抽检、静态 lint |
| 模型幻觉 | 错误回答 | Prompt 约束、低置信度提示人工、引用透明 |
| DashScope 限流 | 请求失败 | 重试、预警、缓存热点问答 |
| 成本失控 | 超预算 | 监控 Token、缓存、压缩上下文 |
| 知识陈旧 | 信息过期 | 建立更新节奏，按 `last_modified_at` 筛选 |
| 渠道语气不一致 | 用户体验受损 | 引入 `persona`/`channel` 约束，测试阶段覆盖多角色脚本 |

## 8. 依赖与假设
- DashScope API Key（Embedding + Chat）可用。
- Postgres + pgvector 已部署可连通。
- 业务方提供脱敏语料，约定更新流程。
- 运维支持日志、监控与备份。

## 9. 里程碑（建议）
1. M1（第 1 周）：需求评审、数据源确认、架构方案。
2. M2（第 2–3 周）：数据清洗 & 入库流程、向量库接入。
3. M3（第 4–5 周）：RAG Pipeline、API 实现、基础监控。
4. M4（第 6 周）：黄金评估集、人工评估、性能调优。
5. M5（第 7 周）：上线准备、运维交接、文档与培训。

---

> 本文档定位为 Stage 1 实施依据，后续阶段（智能客服智能体等）将在此基础上迭代扩展。
